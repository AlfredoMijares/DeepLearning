{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKlEw01CBrSCu6L+SUFId9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlfredoMijares/DeepLearning/blob/main/ProyectoFinal24102024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QhDQOTWH0B2",
        "outputId": "554b6b2e-1b53-4074-f090-b6e925f69d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # This will prompt you to upload kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "Q3GqQtZsIiRh",
        "outputId": "4cd40e1b-e711-4bd8-d3af-b1a64c6fb2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9db743dd-8d92-4bad-81a8-13246b48e306\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9db743dd-8d92-4bad-81a8-13246b48e306\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"alfredomijares\",\"key\":\"7dbb3e86c4f8840a278d4bbc230564b0\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "-nQn2gs-I7J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"hayder17/breast-cancer-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGm5IynMJY-T",
        "outputId": "d0a157e4-d96c-4d0e-cde8-49a3d5a08917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/hayder17/breast-cancer-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 87.2M/87.2M [00:01<00:00, 63.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/hayder17/breast-cancer-detection/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7YAEU8KV6JK"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "1kJlJB7XHyOu",
        "outputId": "368f5a24-1b8b-4ce2-e784-783cac1c1676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-21-e435b63405a7>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-e435b63405a7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    chmod 600 ~/.kaggle/kaggle.json\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading DataSet"
      ],
      "metadata": {
        "id": "mvA2EdJSWDuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "RZ4BX5_9V7UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/kaggle/input/breast-cancer-detection/test'\n",
        "train_path ='/kaggle/input/breast-cancer-detection/train'\n",
        "validation_path ='/kaggle/input/breast-cancer-detection/valid'"
      ],
      "metadata": {
        "id": "5xWWwvrgWKMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = os.listdir('/kaggle/input/breast-cancer-detection/train')\n",
        "print(f\"Class names: {class_names}\")"
      ],
      "metadata": {
        "id": "mwUTh8wLWPiE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "f5bec6fa-8f0a-40c1-ce17-e168c6879a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/breast-cancer-detection/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-71c9acbf181d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/breast-cancer-detection/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Class names: {class_names}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/breast-cancer-detection/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "-Hve_2jGWUx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = generator.flow_from_directory( directory= train_path,\n",
        "                                            target_size = (640,640),\n",
        "                                            batch_size = 50,\n",
        "                                            class_mode= 'binary',\n",
        "                                            shuffle = True)\n",
        "train_data"
      ],
      "metadata": {
        "id": "5KN07XmzWViE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(train_data)\n",
        "\n",
        "print(\"Shape of images:\", images.shape)\n",
        "print(\"Shape of labels:\", labels.shape)"
      ],
      "metadata": {
        "id": "-_xrbEXAWbNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = generator.flow_from_directory(directory = '/kaggle/input/breast-cancer-detection/valid',\n",
        "                                         target_size = (640,640),\n",
        "                                         class_mode = 'binary',\n",
        "                                         shuffle = True,\n",
        "                                        )"
      ],
      "metadata": {
        "id": "mjlYcx1AWeGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(val_data)\n",
        "\n",
        "print(\"Shape of images: \", images.shape)\n",
        "print(\"Labels\", labels.shape)"
      ],
      "metadata": {
        "id": "N9zKth2xWgSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = generator.flow_from_directory(\n",
        "                                        directory= test_path,\n",
        "                                        target_size=(640, 640),\n",
        "                                        batch_size=50,\n",
        "                                        class_mode='binary'\n",
        "                                    )\n",
        "test_data"
      ],
      "metadata": {
        "id": "UcG6J0m3Wj37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "KhiCKbA4Wqvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "plt.figure(1, figsize = (15 , 5))\n",
        "plt.subplot(1, 2 , 1)\n",
        "plt.imshow(cv2.imread('/kaggle/input/breast-cancer-detection/train/0/105_1232990271_png.rf.0d15468a4bec2ad2147f0616b6821681.jpg'))\n",
        "plt.title('0')\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(1, figsize = (15 , 5))\n",
        "plt.subplot(1, 2 , 2)\n",
        "plt.imshow(cv2.imread('/kaggle/input/breast-cancer-detection/train/1/10130_1672636630_png.rf.52c6d1c8c6c58c5c1c5fcaaf57feb81d.jpg'))\n",
        "plt.title('1')"
      ],
      "metadata": {
        "id": "TtjbNnCfWpwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN Model**"
      ],
      "metadata": {
        "id": "18lNrS7dWyZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **¿Qué es una CNN?**\n",
        "\n",
        "Una Red Neuronal Convolucional (CNN) es un tipo de red neuronal diseñada para procesar datos con una estructura de cuadrícula, como imágenes. Las CNN son particularmente eficaces para tareas de visión por computadora, como clasificación de imágenes, detección de objetos y segmentación de imágenes.\n",
        "\n",
        "**Estructura de una CNN**\n",
        "\n",
        "Una CNN se compone de varias capas que trabajan juntas para extraer características de las imágenes y clasificarlas. A continuación se describen las capas más comunes:\n",
        "\n",
        "**Capa de Entrada:**\n",
        "\n",
        "Esta capa recibe la imagen de entrada. Por lo general, las imágenes se representan como tensores de tres dimensiones: altura, ancho y canales de color (por ejemplo, RGB).\n",
        "\n",
        "**Capas Convolucionales:**\n",
        "\n",
        "**- Operación de Convolución:** En esta capa, se aplican filtros (o kernels) que recorren la imagen y realizan la convolución. Cada filtro extrae características específicas, como bordes, texturas o patrones.\n",
        "\n",
        "**- Stride:** Es el paso que da el filtro al moverse sobre la imagen. Un stride mayor reduce el tamaño de la salida.\n",
        "\n",
        "**- Padding:** Se añaden ceros alrededor de la imagen para controlar el tamaño de la salida después de la convolución. El padding \"same\" mantiene el tamaño de la entrada, mientras que \"valid\" lo reduce.\n",
        "\n",
        "**Capa de Activación:**\n",
        "\n",
        "Después de la convolución, se aplica una función de activación, como la ReLU (Rectified Linear Unit). Esta función introduce no linealidades en el modelo, permitiendo que la red aprenda funciones complejas.\n",
        "\n",
        "**Capa de Agrupamiento (Pooling):**\n",
        "\n",
        "Se utiliza para reducir la dimensionalidad y la complejidad computacional. La operación de pooling más común es el max pooling, que toma el valor máximo de una región específica del mapa de características.\n",
        "El pooling ayuda a que la red sea más robusta a variaciones y a evitar el sobreajuste.\n",
        "\n",
        "**Capas Completamente Conectadas (Fully Connected):**\n",
        "\n",
        "Después de varias capas convolucionales y de pooling, las salidas se aplanan y se conectan a capas totalmente conectadas. Estas capas están diseñadas para clasificar las características extraídas.\n",
        "\n",
        "La última capa suele usar una función de activación como Softmax para obtener probabilidades de clase en problemas de clasificación.\n",
        "\n",
        "**Capa de Salida:**\n",
        "\n",
        "Dependiendo de la tarea (por ejemplo, clasificación binaria o multiclase), la capa de salida puede tener uno o más nodos.\n",
        "\n",
        "# **Proceso de Entrenamiento**\n",
        "\n",
        "Forward Pass: La imagen de entrada se pasa a través de la red y se generan predicciones.\n",
        "\n",
        "**Cálculo de Pérdida:** Se calcula la diferencia entre la predicción y la etiqueta real utilizando una función de pérdida (como la entropía cruzada para clasificación).\n",
        "\n",
        "**Backward Pass (Backpropagation):** Se ajustan los pesos de la red utilizando algoritmos de optimización (como SGD o Adam) a través del algoritmo de retropropagación.\n",
        "\n",
        "**Iteración:** Este proceso se repite durante múltiples épocas, ajustando los pesos para mejorar la precisión del modelo.\n",
        "\n",
        "**Ventajas de las CNN**\n",
        "\n",
        "**- Automatización de la Extracción de Características:** A diferencia de las redes neuronales tradicionales, las CNN pueden aprender automáticamente las características más relevantes de los datos sin necesidad de ingeniería manual.\n",
        "\n",
        "**- Invariancia a la Traslación:** Gracias a la convolución y el pooling, las CNN son robustas a pequeñas variaciones en la posición de los objetos en las imágenes.\n",
        "\n",
        "**- Reducción de Parámetros:** La convolución reduce la cantidad de parámetros necesarios en comparación con las redes completamente conectadas, lo que ayuda a prevenir el sobreajuste.\n",
        "\n",
        "**Aplicaciones de las CNN**\n",
        "\n",
        "**- Clasificación de Imágenes:** Identificar la categoría de una imagen (por ejemplo, perro, gato).\n",
        "\n",
        "**- Detección de Objetos:** Localizar y clasificar múltiples objetos dentro de una imagen (por ejemplo, YOLO, SSD).\n",
        "\n",
        "**- Segmentación de Imágenes:** Asignar una etiqueta a cada píxel en la imagen (por ejemplo, U-Net).\n",
        "\n",
        "**- Reconocimiento Facial:** Identificar personas en imágenes o videos.\n",
        "\n",
        "**- Análisis de Video:** Procesar frames de video para detectar acciones o eventos.\n",
        "\n",
        "#**Resumen**\n",
        "\n",
        "Las Redes Neuronales Convolucionales son fundamentales en el campo del Deep Learning y han revolucionado la forma en que abordamos problemas relacionados con imágenes. Su capacidad para aprender características complejas y su estructura eficiente las hacen ideales para tareas de visión por computadora. Con el avance de la tecnología y la disponibilidad de grandes volúmenes de datos, las CNN continúan evolucionando y mejorando en rendimiento."
      ],
      "metadata": {
        "id": "k7fZ4y6bW3EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Build\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(Conv2D(filters = 8, kernel_size= 3, padding='same',\n",
        "                 activation = 'relu' ,input_shape =[640,640,3]))\n",
        "\n",
        "# Pooling Layer\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 16, kernel_size = 3 , activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (3,3)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = 3 , activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size =(3,3)))\n",
        "\n",
        "# Flatten Layer\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "# Fully Connected Layer\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "\n",
        "# Output Layer\n",
        "\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "QiCGSLveWvMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "aT4Ovw4vbX-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "G1RlCfd0bcKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = model.fit(train_data,\n",
        "                          epochs = 10,\n",
        "                          validation_data = val_data)"
      ],
      "metadata": {
        "id": "dlpBDnfzbfLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Results:"
      ],
      "metadata": {
        "id": "7QnwrhF-bmhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history['accuracy'], label = 'Train Data Accuracy')\n",
        "plt.plot(model_history.history['val_accuracy'], label = 'Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "33zvKt2PbmQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "Fj83mfbKbjZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on Validation data\n",
        "val_loss, val_accuracy = model.evaluate(val_data)\n",
        "print(f'Validation accuracy: {val_accuracy}')"
      ],
      "metadata": {
        "id": "Q4krdrOibtZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **keras regularizers**"
      ],
      "metadata": {
        "id": "lH0Fa7tpbwjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los regularizadores en Keras son herramientas utilizadas para prevenir el sobreajuste (overfitting) en modelos de aprendizaje profundo. El sobreajuste ocurre cuando un modelo aprende demasiado bien los datos de entrenamiento, capturando ruido y patrones específicos que no generalizan a datos nuevos. Los regularizadores ayudan a controlar la complejidad del modelo y a mejorar su capacidad de generalización.\n",
        "\n",
        "**Tipos de Regularizadores en Keras**\n",
        "\n",
        "**Regularización L1:**\n",
        "\n",
        "La regularización L1 añade una penalización a la función de pérdida que es proporcional a la suma de los valores absolutos de los pesos. Esto puede llevar a que algunos pesos se vuelvan exactamente cero, lo que resulta en un modelo más esparcido y fácil de interpretar.\n",
        "\n",
        "Fórmula:\n",
        "\n",
        "![Formula uno.png](data:image/png;base64,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)\n",
        "\n",
        "En Keras, se puede aplicar usando keras.regularizers.l1(l=0.01).\n",
        "\n",
        "**Regularización L2:**\n",
        "\n",
        "La regularización L2 añade una penalización proporcional al cuadrado de los pesos. Esto tiende a reducir el valor de todos los pesos, evitando que crezcan demasiado. A diferencia de L1, no lleva a que los pesos se conviertan exactamente en cero, por lo que generalmente no resulta en un modelo esparcido.\n",
        "Fórmula:\n",
        "\n",
        "![Formula dos.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "En Keras, se puede aplicar usando keras.regularizers.l2(l=0.01).\n",
        "\n",
        "**Regularización L1_L2:**\n",
        "\n",
        "Combina ambas penalizaciones L1 y L2. Esto permite obtener las ventajas de ambas: la esparsidad de L1 y la estabilidad de L2.\n",
        "\n",
        "En Keras, se utiliza como keras.regularizers.l1_l2(l1=0.01, l2=0.01).\n",
        "\n",
        "**Efectos de la Regularización**\n",
        "\n",
        "**-Controlar la complejidad:** Al agregar una penalización a los pesos, los modelos tienden a ser menos complejos y más generalizables.\n",
        "\n",
        "**-Prevención del sobreajuste:** Al limitar los pesos, el modelo se vuelve menos sensible a los datos de entrenamiento, lo que ayuda a mejorar su rendimiento en datos no vistos.\n",
        "\n",
        "**Hiperparámetros**\n",
        "\n",
        "Valor de λ (lambda): Este es el coeficiente de regularización que controla la cantidad de penalización. Un valor demasiado alto puede llevar a un modelo que no aprende lo suficiente (underfitting), mientras que un valor demasiado bajo puede no ser efectivo en la prevención del sobreajuste. Es común experimentar con diferentes valores y utilizar técnicas como la validación cruzada para encontrar el mejor.\n",
        "\n",
        "**Otros Métodos de Regularización**\n",
        "\n",
        "Además de los regularizadores de peso, hay otras técnicas de regularización que se pueden usar:\n",
        "\n",
        "**Dropout:** Desactiva aleatoriamente una fracción de las neuronas durante el entrenamiento para evitar que el modelo dependa demasiado de un subconjunto de neuronas.\n",
        "\n",
        "**Early Stopping:** Monitorea el rendimiento del modelo en un conjunto de validación y detiene el entrenamiento cuando el rendimiento deja de mejorar.\n",
        "\n",
        "**Data Augmentation:** Aumenta el tamaño del conjunto de datos de entrenamiento aplicando transformaciones (rotaciones, traslaciones, etc.) a las imágenes.\n",
        "\n",
        "**Conclusión**\n",
        "\n",
        "Los regularizadores en Keras son herramientas poderosas para mejorar la capacidad de generalización de los modelos de aprendizaje profundo. Al aplicar L1, L2 o combinaciones de ambos, puedes ayudar a prevenir el sobreajuste y obtener modelos más robustos. Experimentar con diferentes técnicas y valores de regularización es clave para lograr un buen rendimiento en tareas específicas."
      ],
      "metadata": {
        "id": "qJ8W0VU3cWTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l1\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 8, kernel_size= 3, padding='same',\n",
        "                 kernel_regularizer = l1, activation = 'relu' ,input_shape =[640,640,3]))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 16, kernel_size = 3 , activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (3,3)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = 3 , activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size =(3,3)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "\n",
        "# Output Layer\n",
        "\n",
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "fr4X9LXDb9Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "aVfDY1QcoqTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "PzpKtdBFoxDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = model.fit(train_data,\n",
        "                          epochs = 10,\n",
        "                          validation_data = val_data)"
      ],
      "metadata": {
        "id": "D5N5AKJ9o87q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Results: Regularization**"
      ],
      "metadata": {
        "id": "2WspN9DQpG5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history['accuracy'], label = 'Train Data Accuracy')\n",
        "plt.plot(model_history.history['val_accuracy'], label = 'Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "11XYzSMKpEqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "XSKwkmT9pMHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Transfer learning: VGG19**"
      ],
      "metadata": {
        "id": "Jv-F6la_pb73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG19 es un modelo de red neuronal convolucional que se destaca por su simplicidad y efectividad en tareas de visión por computadora. Fue desarrollado por el Visual Geometry Group (VGG) de la Universidad de Oxford y se presentó en la competición ImageNet Challenge en 2014. Aquí te doy una explicación detallada sobre VGG19, sus características, arquitectura y aplicaciones.\n",
        "\n",
        "#**Características de VGG19**\n",
        "\n",
        "**Profundidad:**\n",
        "\n",
        "VGG19 tiene 19 capas de pesos, de ahí su nombre. Esto incluye 16 capas convolucionales y 3 capas completamente conectadas.\n",
        "\n",
        "**Arquitectura Sencilla:**\n",
        "\n",
        "La arquitectura de VGG19 es notable por su uso de pequeñas convoluciones (3x3) y max pooling, lo que permite mantener la complejidad de la red baja mientras se logra un alto rendimiento.\n",
        "\n",
        "**Uso de ReLU:**\n",
        "\n",
        "Utiliza la función de activación ReLU (Rectified Linear Unit) para introducir no linealidades en el modelo, lo que permite aprender patrones complejos.\n",
        "\n",
        "**Normalización:**\n",
        "\n",
        "Las imágenes de entrada se normalizan utilizando los valores medios de los canales RGB de las imágenes de entrenamiento para centrar los datos.\n",
        "\n",
        "**Transfer Learning:**\n",
        "\n",
        "VGG19 se ha utilizado ampliamente como base para transfer learning debido a su rendimiento en varias tareas de visión por computadora.\n",
        "Arquitectura de VGG19\n",
        "\n",
        "# **La arquitectura de VGG19 se puede desglosar de la siguiente manera:**\n",
        "\n",
        "**Capas Convolucionales:**\n",
        "\n",
        "La red comienza con una serie de capas convolucionales que aplican filtros de 3x3 en la entrada. Las capas convolucionales están organizadas en bloques, donde cada bloque tiene múltiples capas convolucionales seguidas de una capa de max pooling.\n",
        "\n",
        "**Capas de Max Pooling:**\n",
        "\n",
        "Después de cada bloque de convolución, se aplica una capa de max pooling (2x2) con un stride de 2. Esto reduce las dimensiones espaciales de las características extraídas y ayuda a capturar la información más relevante.\n",
        "\n",
        "**Capas Completamente Conectadas:**\n",
        "\n",
        "Al final de las capas convolucionales y de pooling, las características se aplanan y se conectan a dos capas densas de 4096 neuronas, seguidas de una tercera capa de salida que utiliza la función de activación softmax para clasificar las imágenes en múltiples categorías.\n",
        "\n",
        "**Diagrama de VGG19**\n",
        "\n",
        "Si quisieras visualizar VGG19, generalmente se representa con bloques que indican las capas convolucionales, las operaciones de pooling y las capas densas. Aquí hay un resumen de la estructura:\n",
        "\n",
        "Input (224x224x3)\n",
        "    ↓\n",
        "Conv3-64\n",
        "    ↓\n",
        "Conv3-64\n",
        "    ↓\n",
        "MaxPooling (2x2)\n",
        "    ↓\n",
        "Conv3-128\n",
        "    ↓\n",
        "Conv3-128\n",
        "    ↓\n",
        "MaxPooling (2x2)\n",
        "    ↓\n",
        "Conv3-256\n",
        "    ↓\n",
        "Conv3-256\n",
        "    ↓\n",
        "Conv3-256\n",
        "    ↓\n",
        "MaxPooling (2x2)\n",
        "    ↓\n",
        "Conv3-512\n",
        "    ↓\n",
        "Conv3-512\n",
        "    ↓\n",
        "Conv3-512\n",
        "    ↓\n",
        "MaxPooling (2x2)\n",
        "    ↓\n",
        "Conv3-512\n",
        "    ↓\n",
        "Conv3-512\n",
        "    ↓\n",
        "Conv3-512\n",
        "    ↓\n",
        "MaxPooling (2x2)\n",
        "    ↓\n",
        "Flatten\n",
        "    ↓\n",
        "Dense (4096)\n",
        "    ↓\n",
        "Dense (4096)\n",
        "    ↓\n",
        "Dense (n_classes, Softmax)\n",
        "\n",
        "\n",
        "#**Aplicaciones de VGG19**\n",
        "\n",
        "**Clasificación de Imágenes:** VGG19 se ha utilizado con éxito en tareas de clasificación de imágenes, como la clasificación de objetos en el conjunto de datos ImageNet.\n",
        "\n",
        "**Transfer Learning:** Debido a su arquitectura preentrenada, VGG19 se usa frecuentemente para transferir el aprendizaje a nuevos conjuntos de datos, permitiendo obtener buenos resultados incluso con pocos datos.\n",
        "\n",
        "**Detección de Objetos:** Se ha adaptado para modelos de detección de objetos, como Faster R-CNN.\n",
        "\n",
        "**Segmentación de Imágenes:** Puede ser utilizado como base para modelos de segmentación, como U-Net.\n",
        "\n",
        "#**Ventajas y Desventajas**\n",
        "\n",
        "**Ventajas:**\n",
        "\n",
        "**Simplicidad:** La arquitectura es fácil de entender y de implementar.\n",
        "\n",
        "**Rendimiento:** Ofrece un rendimiento sólido en tareas de clasificación de imágenes.\n",
        "\n",
        "**Flexibilidad:** Se puede usar para transfer learning y adaptarse a diferentes tareas.\n",
        "\n",
        "**Desventajas:**\n",
        "\n",
        "**Requerimientos Computacionales:** Es un modelo bastante pesado en términos de memoria y potencia de cálculo.\n",
        "\n",
        "**No es la Más Moderna:** Existen modelos más recientes (como ResNet, Inception) que superan su rendimiento y eficiencia.\n",
        "\n",
        "**Conclusión**\n",
        "\n",
        "VGG19 es un modelo icónico en el campo del aprendizaje profundo, conocido por su arquitectura efectiva y su rendimiento en competiciones de visión por computadora. Aunque ha sido superado por modelos más avanzados, sigue siendo una base sólida para el aprendizaje y la aplicación en diversas tareas de visión por computadora."
      ],
      "metadata": {
        "id": "zp8ajAATpgZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = generator.flow_from_directory( directory= train_path,\n",
        "                                            target_size = (240,240),\n",
        "                                            class_mode= 'binary',\n",
        "                                            shuffle = True)\n",
        "\n",
        "val_data = generator.flow_from_directory( directory= validation_path,\n",
        "                                            target_size = (240,240),\n",
        "                                            class_mode= 'binary',\n",
        "                                            shuffle = True)\n",
        "\n",
        "test_data = generator.flow_from_directory( directory= test_path,\n",
        "                                            target_size = (240,240),\n",
        "                                            class_mode= 'binary')"
      ],
      "metadata": {
        "id": "a-h_4i09pbaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Model\n",
        "\n",
        "vgg19 = VGG19()\n",
        "vgg19.summary()"
      ],
      "metadata": {
        "id": "GCekncQIpO_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG19(include_top=False, input_shape=(240, 240, 3))"
      ],
      "metadata": {
        "id": "32JLpcNCo-aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1, activation='sigmoid')(x)"
      ],
      "metadata": {
        "id": "KnM0F4QEr0JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=base_model.input, outputs=x)"
      ],
      "metadata": {
        "id": "B9tKpEAEr2J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "PIuehIUyr4ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = model.fit(train_data,\n",
        "                          epochs = 10,\n",
        "                          validation_data = val_data)"
      ],
      "metadata": {
        "id": "ASdZPuFFr654"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results : Transfer Learning"
      ],
      "metadata": {
        "id": "EvoCsKEysADh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history['accuracy'], label = 'Train Data Accuracy')\n",
        "plt.plot(model_history.history['val_accuracy'], label = 'Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IEu3Ca7Ur9jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "f8NLycQmsD2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on Validation data\n",
        "val_loss, val_accuracy = model.evaluate(val_data)\n",
        "print(f'Validation accuracy: {val_accuracy}')"
      ],
      "metadata": {
        "id": "z2wuafqFsILP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transfer Learning : RESNet50**"
      ],
      "metadata": {
        "id": "6evYOxm1-lef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50 es una arquitectura de red neuronal profunda desarrollada por Kaiming He y su equipo en 2015, que ha sido ampliamente utilizada en tareas de visión por computadora. La clave de ResNet es el uso de \"bloques residuales\", que permiten la creación de redes mucho más profundas sin el problema del desvanecimiento del gradiente.\n",
        "\n",
        "#**Detalles sobre ResNet50**\n",
        "\n",
        "#**1. Arquitectura**\n",
        "\n",
        "ResNet50 es una red neuronal que consta de 50 capas. Su arquitectura se basa en bloques residuales que permiten que la entrada de una capa se sume a la salida de la misma capa. Esto se realiza mediante conexiones de \"salto\" (skip connections), que facilitan el flujo del gradiente durante el entrenamiento.\n",
        "\n",
        "#**2. Bloques Residuales**\n",
        "\n",
        "Un bloque residual típico tiene la siguiente estructura:\n",
        "\n",
        "**Entrada:** La entrada de la capa.\n",
        "\n",
        "**Convoluciones:** Aplicación de convoluciones 2D, seguidas de activaciones ReLU.\n",
        "\n",
        "**Suma:** La entrada original se suma a la salida de las convoluciones.\n",
        "\n",
        "**Salida:** La suma se pasa a través de otra activación ReLU.\n",
        "Esto permite que la red aprenda la función de identidad, lo que facilita el entrenamiento de redes más profundas.\n",
        "\n",
        "#**3. Capas**\n",
        "\n",
        "ResNet50 está formada por varios tipos de capas:\n",
        "\n",
        "**Convolucionales:** Usadas para extraer características de las imágenes.\n",
        "\n",
        "**Batch Normalization:** Normaliza las salidas de las capas anteriores para mejorar la estabilidad y velocidad del entrenamiento.\n",
        "\n",
        "**ReLU:** Función de activación que introduce no linealidad en el modelo.\n",
        "\n",
        "**Pooling:** Generalmente se utiliza max pooling para reducir la dimensionalidad de las características extraídas.\n",
        "\n",
        "#**4. Ventajas**\n",
        "\n",
        "**Profundidad:** ResNet permite construir redes mucho más profundas (por ejemplo, ResNet101, ResNet152) sin problemas significativos de entrenamiento.\n",
        "\n",
        "**Mejor rendimiento:** Ha demostrado ser muy efectiva en tareas de clasificación de imágenes, logrando resultados sobresalientes en competiciones como ImageNet.\n",
        "\n",
        "**Flexibilidad:** Puede ser adaptada a diferentes tareas, como detección de objetos y segmentación, simplemente cambiando la parte superior de la red.\n",
        "\n",
        "#**Conclusión**\n",
        "ResNet50 es una de las arquitecturas más influyentes en la visión por computadora y ha servido como base para muchas investigaciones y desarrollos posteriores. Su diseño innovador ha permitido el avance en la creación de modelos más profundos y precisos, haciendo que sea una elección popular para diversas aplicaciones."
      ],
      "metadata": {
        "id": "-xlgQCWl-sTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "2T1CMc5T-ram"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = ResNet50(weights='imagenet', include_top=False, input_shape=(240, 240, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "E77kbsyR_M5U",
        "outputId": "4fe6bbab-5af2-4315-9676-5c7c95b47fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d373ca06bf47>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Results : Transfer Learning (Plot Accuracy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Data Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = generator.flow_from_directory( directory= train_path,\n",
        "                                            target_size = (240,240),\n",
        "                                            class_mode= 'binary',\n",
        "                                            shuffle = True)\n",
        "\n",
        "val_data = generator.flow_from_directory( directory= validation_path,\n",
        "                                            target_size = (240,240),\n",
        "                                            class_mode= 'binary',\n",
        "                                            shuffle = True)\n",
        "\n",
        "test_data = generator.flow_from_directory( directory= test_path,\n",
        "                                            target_size = (240,240),\n",
        "                                            class_mode= 'binary')"
      ],
      "metadata": {
        "id": "FZS8sxD4_krZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = resnet50_model.output\n",
        "x = Flatten()(x)\n",
        "output_layer = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the complete model\n",
        "model = Model(inputs=resnet50_model.input, outputs=output_layer)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BZNx1UH__3W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.samples"
      ],
      "metadata": {
        "id": "JHGWulqh_58X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hHIsCO5o_7_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model_history = model.fit( train_data,\n",
        "                epochs = 35 ,\n",
        "                validation_data = val_data)"
      ],
      "metadata": {
        "id": "t83Xa_Jb_-EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history['accuracy'], label = 'Train Data Accuracy')\n",
        "plt.plot(model_history.history['val_accuracy'], label = 'Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iK_SSmY6ADIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "F-molA1MADzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "Qu_Xm_66AGf-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}